{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Required Libraries"
      ],
      "metadata": {
        "id": "vKr9ESo8v332"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2rDg549lsKL1",
        "outputId": "4c33d36c-b3c7-40cb-92f8-5bf9ca54b5b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n",
            "Collecting langchain-ibm\n",
            "  Downloading langchain_ibm-0.3.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting ibm-watsonx-ai<2.0.0,>=1.1.16 (from langchain-ibm)\n",
            "  Downloading ibm_watsonx_ai-1.2.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-ibm) (0.3.29)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (2.32.3)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (0.28.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (2.3.0)\n",
            "Collecting pandas<2.2.0,>=0.24.2 (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm)\n",
            "  Downloading pandas-2.1.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (2024.12.14)\n",
            "Collecting lomond (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm)\n",
            "  Downloading lomond-0.3.3-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (24.2)\n",
            "Collecting ibm-cos-sdk<2.14.0,>=2.12.0 (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm)\n",
            "  Downloading ibm-cos-sdk-2.13.6.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm) (0.2.10)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm) (2.10.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-ibm) (4.12.2)\n",
            "Collecting ibm-cos-sdk-core==2.13.6 (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm)\n",
            "  Downloading ibm-cos-sdk-core-2.13.6.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ibm-cos-sdk-s3transfer==2.13.6 (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm)\n",
            "  Downloading ibm-cos-sdk-s3transfer-2.13.6.tar.gz (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<=1.0.1,>=0.10.0 (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting python-dateutil<3.0.0,>=2.9.0 (from ibm-cos-sdk-core==2.13.6->ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting requests (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm)\n",
            "  Downloading requests-2.32.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-ibm) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-ibm) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-ibm) (1.0.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (0.14.0)\n",
            "Requirement already satisfied: numpy<2,>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-ibm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-ibm) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (3.4.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (3.21.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from lomond->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (1.3.1)\n",
            "Downloading langchain_ibm-0.3.5-py3-none-any.whl (24 kB)\n",
            "Downloading ibm_watsonx_ai-1.2.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.1.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lomond-0.3.3-py2.py3-none-any.whl (35 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ibm-cos-sdk, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n",
            "  Building wheel for ibm-cos-sdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk: filename=ibm_cos_sdk-2.13.6-py3-none-any.whl size=77231 sha256=626d5768ad51a7981e6d15a405e3f9307a793dea909344a2d33a9fd269ae2a44\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/8c/76/f9472a53a2a80da414dd53ca55f08dbfe48ed6de76e51e3d5f\n",
            "  Building wheel for ibm-cos-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-core: filename=ibm_cos_sdk_core-2.13.6-py3-none-any.whl size=661459 sha256=720188a6cb7c45eaf1994c238d5743d3911cca7aeffd47e736f6004ebfcd7d28\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/8e/58/e0fdc8135343f394de9c98a48ed20adf698600e01b16ea46bc\n",
            "  Building wheel for ibm-cos-sdk-s3transfer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-s3transfer: filename=ibm_cos_sdk_s3transfer-2.13.6-py3-none-any.whl size=90204 sha256=0f6110bc5b507cdbdd6d4316cea488056e4ced5beb983c79f6bbd06dfb9ad386\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/71/63/176f15a501fd18265938e1c0b2928f9f380b96e3fc15680c80\n",
            "Successfully built ibm-cos-sdk ibm-cos-sdk-core ibm-cos-sdk-s3transfer\n",
            "Installing collected packages: requests, python-dateutil, lomond, jmespath, pandas, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, ibm-cos-sdk, ibm-watsonx-ai, langchain-ibm\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.2 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ibm-cos-sdk-2.13.6 ibm-cos-sdk-core-2.13.6 ibm-cos-sdk-s3transfer-2.13.6 ibm-watsonx-ai-1.2.1 jmespath-1.0.1 langchain-ibm-0.3.5 lomond-0.3.3 pandas-2.1.4 python-dateutil-2.9.0.post0 requests-2.32.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil"
                ]
              },
              "id": "63365c755dd5432d919d8d224eaac8bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ibm-watsonx-ai in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.32.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (0.28.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.3.0)\n",
            "Requirement already satisfied: pandas<2.2.0,>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.1.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2024.12.14)\n",
            "Requirement already satisfied: lomond in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (0.3.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (24.2)\n",
            "Requirement already satisfied: ibm-cos-sdk<2.14.0,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.13.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (8.5.0)\n",
            "Requirement already satisfied: ibm-cos-sdk-core==2.13.6 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai) (2.13.6)\n",
            "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.13.6 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai) (2.13.6)\n",
            "Requirement already satisfied: jmespath<=1.0.1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk-core==2.13.6->ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai) (2.9.0.post0)\n",
            "Requirement already satisfied: numpy<2,>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ibm-watsonx-ai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ibm-watsonx-ai) (3.10)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->ibm-watsonx-ai) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->ibm-watsonx-ai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->ibm-watsonx-ai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->ibm-watsonx-ai) (3.21.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from lomond->ibm-watsonx-ai) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->ibm-watsonx-ai) (1.3.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.29)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (2.10.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.14 marshmallow-3.25.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.9.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0.post1\n",
            "Collecting smolagents\n",
            "  Downloading smolagents-1.4.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: transformers>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from smolagents) (4.47.1)\n",
            "Collecting requests>=2.32.3 (from smolagents)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.11/dist-packages (from smolagents) (13.9.4)\n",
            "Collecting pandas>=2.2.3 (from smolagents)\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from smolagents) (3.1.5)\n",
            "Requirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from smolagents) (11.1.0)\n",
            "Collecting markdownify>=0.14.1 (from smolagents)\n",
            "  Downloading markdownify-0.14.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting gradio>=5.8.0 (from smolagents)\n",
            "  Downloading gradio-5.12.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting duckduckgo-search>=6.3.7 (from smolagents)\n",
            "  Downloading duckduckgo_search-7.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from smolagents) (1.0.1)\n",
            "Collecting e2b-code-interpreter>=1.0.3 (from smolagents)\n",
            "  Downloading e2b_code_interpreter-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from smolagents) (0.20.1+cu121)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search>=6.3.7->smolagents) (8.1.8)\n",
            "Collecting primp>=0.10.0 (from duckduckgo-search>=6.3.7->smolagents)\n",
            "  Downloading primp-0.10.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search>=6.3.7->smolagents) (5.3.0)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.11/dist-packages (from e2b-code-interpreter>=1.0.3->smolagents) (24.3.0)\n",
            "Collecting e2b<2.0.0,>=1.0.4 (from e2b-code-interpreter>=1.0.3->smolagents)\n",
            "  Downloading e2b-1.0.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from e2b-code-interpreter>=1.0.3->smolagents) (0.28.1)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio>=5.8.0->smolagents)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=5.8.0->smolagents) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio>=5.8.0->smolagents)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio>=5.8.0->smolagents)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.4 (from gradio>=5.8.0->smolagents)\n",
            "  Downloading gradio_client-1.5.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio>=5.8.0->smolagents) (0.27.1)\n",
            "Collecting markupsafe~=2.0 (from gradio>=5.8.0->smolagents)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=5.8.0->smolagents) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=5.8.0->smolagents) (3.10.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio>=5.8.0->smolagents) (24.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=5.8.0->smolagents) (2.10.5)\n",
            "Collecting pydub (from gradio>=5.8.0->smolagents)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio>=5.8.0->smolagents)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=5.8.0->smolagents) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio>=5.8.0->smolagents)\n",
            "  Downloading ruff-0.9.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio>=5.8.0->smolagents)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio>=5.8.0->smolagents)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio>=5.8.0->smolagents)\n",
            "  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio>=5.8.0->smolagents)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio>=5.8.0->smolagents) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=5.8.0->smolagents) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio>=5.8.0->smolagents)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio>=5.8.0->smolagents) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio>=5.8.0->smolagents) (14.1)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /usr/local/lib/python3.11/dist-packages (from markdownify>=0.14.1->smolagents) (4.12.3)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.11/dist-packages (from markdownify>=0.14.1->smolagents) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->smolagents) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->smolagents) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->smolagents) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->smolagents) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->smolagents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->smolagents) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->smolagents) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->smolagents) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->smolagents) (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0.0->smolagents) (3.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0.0->smolagents) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0.0->smolagents) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0.0->smolagents) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0.0->smolagents) (4.67.1)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from torchvision->smolagents) (2.5.1+cu121)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->smolagents) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->smolagents) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->smolagents) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->smolagents) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->smolagents) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->smolagents) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->smolagents) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->smolagents) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->smolagents) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->smolagents) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->smolagents) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->smolagents) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->smolagents) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->smolagents) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.5.1->torchvision->smolagents) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision->smolagents) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio>=5.8.0->smolagents) (1.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.9->markdownify>=0.14.1->smolagents) (2.6)\n",
            "Requirement already satisfied: httpcore<2.0.0,>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from e2b<2.0.0,>=1.0.4->e2b-code-interpreter>=1.0.3->smolagents) (1.0.7)\n",
            "Requirement already satisfied: protobuf<6.0.0,>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from e2b<2.0.0,>=1.0.4->e2b-code-interpreter>=1.0.3->smolagents) (4.25.5)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio>=5.8.0->smolagents)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore<2.0.0,>=1.0.5->e2b<2.0.0,>=1.0.4->e2b-code-interpreter>=1.0.3->smolagents) (0.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->smolagents) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio>=5.8.0->smolagents) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio>=5.8.0->smolagents) (2.27.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio>=5.8.0->smolagents) (1.5.4)\n",
            "Downloading smolagents-1.4.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading duckduckgo_search-7.2.1-py3-none-any.whl (19 kB)\n",
            "Downloading e2b_code_interpreter-1.0.3-py3-none-any.whl (12 kB)\n",
            "Downloading gradio-5.12.0-py3-none-any.whl (57.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.4-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.4/321.4 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdownify-0.14.1-py3-none-any.whl (11 kB)\n",
            "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading e2b-1.0.5-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.7/81.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading primp-0.10.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, requests, python-multipart, primp, markupsafe, ffmpy, aiofiles, starlette, pandas, markdownify, duckduckgo-search, safehttpx, gradio-client, fastapi, e2b, gradio, e2b-code-interpreter, smolagents\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.2\n",
            "    Uninstalling requests-2.32.2:\n",
            "      Successfully uninstalled requests-2.32.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibm-watsonx-ai 1.2.1 requires pandas<2.2.0,>=0.24.2, but you have pandas 2.2.3 which is incompatible.\n",
            "ibm-cos-sdk-core 2.13.6 requires requests<2.32.3,>=2.32.0, but you have requests 2.32.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 duckduckgo-search-7.2.1 e2b-1.0.5 e2b-code-interpreter-1.0.3 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.12.0 gradio-client-1.5.4 markdownify-0.14.1 markupsafe-2.1.5 pandas-2.2.3 primp-0.10.1 pydub-0.25.1 python-multipart-0.0.20 requests-2.32.3 ruff-0.9.2 safehttpx-0.1.6 semantic-version-2.10.0 smolagents-1.4.1 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install required packages\n",
        "!pip install PyPDF2\n",
        "!pip install pdfplumber\n",
        "!pip install langchain-ibm\n",
        "!pip install ibm-watsonx-ai\n",
        "!pip install langchain\n",
        "!pip install --upgrade langchain-community\n",
        "!pip install faiss-cpu\n",
        "!pip install smolagents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standardized Pipeline Definition\n",
        "\n",
        "We define a standardized pipeline for processing all documents, enforcing compliance with the required JSON structure. The pipeline remains consistent across all PDFs, while prompts are customized to extract data specific to each use case. To ensure accurate extraction and minimize error propagation in subsequent pipeline stages, we utilize Mistral Large for processing. The extracted data is then ingested and aggregated in later steps of the pipeline."
      ],
      "metadata": {
        "id": "Qk-wnRQjvPdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import required libraries\n",
        "import PyPDF2\n",
        "import pdfplumber\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "from typing import Optional, Dict, List\n",
        "from pathlib import Path\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class PDFProcessor:\n",
        "    \"\"\"A class to handle PDF to text conversion using multiple backends.\"\"\"\n",
        "\n",
        "    # [Previous implementation remains the same]\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the PDF processor.\"\"\"\n",
        "        self.text_cache: Dict[str, str] = {}\n",
        "\n",
        "    def extract_with_pdfplumber(self, file_path: str) -> Optional[str]:\n",
        "        \"\"\"Extract text using pdfplumber.\"\"\"\n",
        "        try:\n",
        "            with pdfplumber.open(file_path) as pdf:\n",
        "                pages = [page.extract_text() or '' for page in pdf.pages]\n",
        "                return '\\n'.join(pages)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error extracting text with pdfplumber: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def extract_with_pypdf2(self, file_path: str) -> Optional[str]:\n",
        "        \"\"\"Extract text using PyPDF2 as fallback.\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'rb') as file:\n",
        "                reader = PyPDF2.PdfReader(file)\n",
        "                pages = [page.extract_text() or '' for page in reader.pages]\n",
        "                return '\\n'.join(pages)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error extracting text with PyPDF2: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def process_pdf(self, file_path: str) -> Optional[str]:\n",
        "        \"\"\"Process a single PDF file.\"\"\"\n",
        "        if not os.path.exists(file_path):\n",
        "            logger.error(f\"File not found: {file_path}\")\n",
        "            return None\n",
        "\n",
        "        if file_path in self.text_cache:\n",
        "            return self.text_cache[file_path]\n",
        "\n",
        "        text = self.extract_with_pdfplumber(file_path) or self.extract_with_pypdf2(file_path)\n",
        "\n",
        "        if text is None:\n",
        "            logger.error(f\"All extraction methods failed for {file_path}\")\n",
        "            return None\n",
        "\n",
        "        self.text_cache[file_path] = text\n",
        "        return text"
      ],
      "metadata": {
        "id": "l3-lutynsf5H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: WatsonX LLM Configuration\n",
        "from ibm_watsonx_ai import Credentials\n",
        "from langchain_ibm import WatsonxLLM\n",
        "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
        "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
        "\n",
        "class WatsonXProcessor:\n",
        "    \"\"\"Class to handle WatsonX LLM processing.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize WatsonX processor with credentials and parameters.\"\"\"\n",
        "        self.project_id = \"44241d2e-6cff-49ce-b84c-1ed230f8eb36\"\n",
        "        self.api_key = \"DZKT0-JkhDNn9_o6a_N3AiYk06HEifU3Kh6xnWXo16v-\"\n",
        "        self.credentials = Credentials(\n",
        "            url=\"https://us-south.ml.cloud.ibm.com/\",\n",
        "            api_key=self.api_key\n",
        "        )\n",
        "\n",
        "        # Model configuration\n",
        "        self.model_id = 'mistralai/mistral-large'\n",
        "        self.parameters = {\n",
        "            GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
        "            GenParams.MIN_NEW_TOKENS: 1,\n",
        "            GenParams.MAX_NEW_TOKENS: 8192,\n",
        "            GenParams.STOP_SEQUENCES: [\"<|endoftext|>\"],\n",
        "            GenParams.TEMPERATURE: 0.9,\n",
        "            GenParams.TOP_P: 0.9\n",
        "        }\n",
        "\n",
        "        # Initialize LLM\n",
        "        self.llm = WatsonxLLM(\n",
        "            model_id=self.model_id,\n",
        "            url=self.credentials.get(\"url\"),\n",
        "            apikey=self.credentials.get(\"apikey\"),\n",
        "            project_id=self.project_id,\n",
        "            params=self.parameters\n",
        "        )\n",
        "\n",
        "    def generate_response(self, prompt: str) -> str:\n",
        "        \"\"\"Generate response using WatsonX LLM.\"\"\"\n",
        "        formatted_prompt = f\"<s>[INST] {prompt} [/INST]\"\n",
        "        try:\n",
        "            response = self.llm.invoke(formatted_prompt)\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating response: {str(e)}\")\n",
        "            return f\"Error generating response: {str(e)}\""
      ],
      "metadata": {
        "id": "sAPuRN-nsjeg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Batch Processing Pipeline\n",
        "class MenuExtractionPipeline:\n",
        "    \"\"\"Pipeline for processing multiple PDFs and extracting menu information.\"\"\"\n",
        "\n",
        "    def __init__(self, output_dir: str):\n",
        "        \"\"\"Initialize pipeline components.\"\"\"\n",
        "        self.pdf_processor = PDFProcessor()\n",
        "        self.llm_processor = WatsonXProcessor()\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def process_single_file(self, pdf_path: str, prompt: str) -> None:\n",
        "        \"\"\"Process a single PDF file and save its output.\"\"\"\n",
        "        logger.info(f\"Processing {pdf_path}\")\n",
        "\n",
        "        # Extract text from PDF\n",
        "        pdf_text = self.pdf_processor.process_pdf(pdf_path)\n",
        "        if not pdf_text:\n",
        "            logger.error(f\"Failed to extract text from {pdf_path}\")\n",
        "            return\n",
        "\n",
        "        # Generate full prompt\n",
        "        full_prompt = f\"\"\"Dato il seguente testo:\n",
        "\n",
        "        {pdf_text}\n",
        "\n",
        "        {prompt}\"\"\"\n",
        "\n",
        "        # Generate response\n",
        "        response = self.llm_processor.generate_response(full_prompt)\n",
        "\n",
        "        # Save output\n",
        "        output_path = self.output_dir / f\"{Path(pdf_path).stem}_menu.json\"\n",
        "        try:\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump({\"text\": response}, f, ensure_ascii=False, indent=2)\n",
        "            logger.info(f\"Saved output to {output_path}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error saving output for {pdf_path}: {str(e)}\")\n",
        "\n",
        "    def process_directory(self, input_dir: str, prompt: str) -> None:\n",
        "        \"\"\"Process all PDF files in a directory.\"\"\"\n",
        "        input_path = Path(input_dir)\n",
        "        if not input_path.exists():\n",
        "            logger.error(f\"Input directory {input_dir} does not exist\")\n",
        "            return\n",
        "\n",
        "        pdf_files = list(input_path.glob(\"*.pdf\"))\n",
        "        logger.info(f\"Found {len(pdf_files)} PDF files in {input_dir}\")\n",
        "\n",
        "        for pdf_file in pdf_files:\n",
        "            self.process_single_file(str(pdf_file), prompt)"
      ],
      "metadata": {
        "id": "yvr7uzEks3ZJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automated Extraction Pipelines\n",
        "\n",
        "We define three distinct, partially and fully automated extraction pipelines to maintain high accuracy during the extraction phase:\n",
        "\n",
        "1. **Metadata Extraction Pipeline**: Extracts metadata from documents, ensuring the foundational information is accurately captured.\n",
        "\n",
        "2. **Ingredients and Techniques Extraction Pipeline**: Focuses on extracting ingredients and culinary techniques from menu documents.\n",
        "\n",
        "3. **Constrained Extraction Pipeline**: Operates after processing all well-formatted, standardized, and uncorrupted documents. It informs the model of the known ingredients and techniques to guide and constrain the extraction process, achieving more effective and accurate results.\n",
        "\n",
        "These pipelines work cohesively to optimize data extraction and ensure the integrity of the processed information."
      ],
      "metadata": {
        "id": "8M0uARlnwVLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Prompt Definitions\n",
        "\n",
        "EXTRACTION_CONFIGS = {\n",
        "    \"metadata\": {\n",
        "        \"name\": \"Restaurant Metadata Extraction\",\n",
        "        \"prompt\": \"\"\"Estrai da un PDF informazioni relative a ristoranti, restituendo un output in formato JSON con i seguenti dettagli per ogni ristorante:\n",
        "\n",
        "- Nome del ristorante (dal titolo)\n",
        "- Nome dello chef (sotto il titolo)\n",
        "- Nome del pianeta (se presente)\n",
        "- Licenze e skills in forma di elenco\n",
        "- Tecnologie in forma di elenco\n",
        "\n",
        "L'output deve avere questa struttura:\n",
        "\n",
        "{\n",
        "  \"Nome_ristorante\": \"<nome_del_ristorante>\",\n",
        "  \"Nome_chef\": \"<nome_dello_chef>\",\n",
        "  \"Nome_pianeta\": \"<nome_del_pianeta>\",\n",
        "  \"Licenze\": [\n",
        "    \"<licenza 1>\",\n",
        "    \"<licenza 2>\",\n",
        "    ...\n",
        "  ],\n",
        "  \"Ordini\": [\n",
        "    \"<ordine 1>\",\n",
        "    \"<ordine 2>\",\n",
        "    ...\n",
        "  ]\n",
        "}\"\"\",\n",
        "        \"output_dir\": \"/content/Extracted_Metadata\",\n",
        "        \"description\": \"Extracts restaurant metadata including name, chef, planet, and certifications\"\n",
        "    },\n",
        "\n",
        "    \"menu_basic\": {\n",
        "        \"name\": \"Basic Menu Extraction\",\n",
        "        \"prompt\": \"\"\"Estrai da un PDF un menu composto da più piatti, restituendo un output in formato JSON in cui ogni piatto è rappresentato con il nome, gli ingredienti e le tecniche utilizzate per la preparazione. L'output deve avere questa struttura:\n",
        "{\n",
        "  \"<Nome Piatto>\": {\n",
        "    \"Ingredienti\": [\n",
        "      \"<Ingrediente1>\",\n",
        "      \"<Ingrediente2>\",\n",
        "      ...\n",
        "    ],\n",
        "    \"Tecniche\": [\n",
        "      \"<Tecnica1>\",\n",
        "      \"<Tecnica2>\",\n",
        "      ...\n",
        "    ]\n",
        "  }\n",
        "}\"\"\",\n",
        "        \"output_dir\": \"/content/Extracted_Basic_Menu\",\n",
        "        \"description\": \"Extracts menu items with ingredients and techniques\"\n",
        "    },\n",
        "\n",
        "    \"menu_constrained\": {\n",
        "        \"name\": \"Constrained Menu Extraction\",\n",
        "        \"prompt\": \"\"\"Estrai dal testo un menu composto da più piatti, restituendo un output in formato JSON in cui ogni piatto è rappresentato con il nome, gli ingredienti e le tecniche utilizzate per la preparazione. L'output deve avere questa struttura:\n",
        "{\n",
        "  \"<Nome Piatto>\": {\n",
        "    \"Ingredienti\": [\n",
        "      \"<Ingrediente1>\",\n",
        "      \"<Ingrediente2>\",\n",
        "      ...\n",
        "    ],\n",
        "    \"Tecniche\": [\n",
        "      \"<Tecnica1>\",\n",
        "      \"<Tecnica2>\",\n",
        "      ...\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "Assicurati di analizzare correttamente il testo per individuare i nomi dei piatti, le sezioni relative agli ingredienti e quelle relative alle tecniche.\n",
        "\n",
        "Di seguito trovi l'elenco degli ingredienti esistenti:\n",
        "{Affettamento a Pulsazioni Quantistiche, Affumicatura Polarizzata a Freddo Iperbarico, Affumicatura Psionica Sensoriale, Affumicatura Temporale Risonante, Affumicatura a Stratificazione Quantica, Affumicatura tramite Big Bang Microcosmico, Amalgamazione Sintetica Molecolare, Bollitura Entropica Sincronizzata, Bollitura Infrasonica Armonizzata, Bollitura Termografica a Rotazione Veloce, Congelamento Bio-Luminiscente Sincronico, Congelazione Iperdimensionalmente Stratificata, Cottura Idrodinamica Autoregolante, Cottura Olografica Quantum Fluttuante, Cottura Sottovuoto Antimateria, Cottura Sottovuoto Bioma Sintetico, Cottura Sottovuoto Frugale Energeticamente Negativa, Cottura Sottovuoto Multirealità Collassante, Cottura Sottovuoto Pulsar Magnetica, Cottura a Forno Dinamico Inversionale, Cottura a Vapore Ecodinamico Bilanciato, Cottura a Vapore Risonante Simbiotico, Cottura a Vapore Termocinetica Multipla, Cottura a Vapore con Flusso di Particelle Isoarmoniche, Cottura al Forno con Paradosso Temporale Cronospeculare, Cottura con Microonde Entropiche Sincronizzate, Cryo-Tessitura Energetica Polarizzata, Decostruzione Ancestrale, Decostruzione Atomica a Strati Energetici, Decostruzione Interdimensionale Lovecraftiana, Decostruzione Magnetica Risonante, Ebollizione Magneto-Cinetica Pulsante, Fermentazione Psionica Energetica, Fermentazione Quantica a Strati Multiversali, Fermentazione Quantico Biometrica, Fermentazione Temporale Sincronizzata, Grigliatura Eletro-Molecolare a Spaziatura Variabile, Grigliatura Plasma Sintetico Risonante, Grigliatura Psionica Dinamica Ritmica, Idro-Cristallizzazione Sonora Quantistica, Impasto Gravitazionale Vorticoso, Impasto a Campi Magnetici Dualistici, Incisione Elettromagnetica Plasmica, Marinatura Psionica, Marinatura Sotto Zero a Polarità Inversa, Marinatura Temporale Sincronizzata, Marinatura a Infusione Gravitazionale, Marinatura tramite Reazioni d'Antimateria Diluite, Modellatura Onirica Tetrazionale, Saltare in Padella Classica, Saltare in Padella Realtà Energetiche Parallele, Saltare in Padella Singolarità Inversa, Sferificazione Cromatica Interdimensionale, Sferificazione Filamentare a Molecole Vibrazionali, Sferificazione a Gravità Psionica Variabile, Sferificazione con Campi Magnetici Entropici, Sferificazione tramite Matrici Biofotiche, Sinergia Elettro-Osmotica Programmabile, Surgelamento Antimaterico a Risonanza Inversa, Taglio Dimensionale a Lame Fotofiliche, Taglio Sinaptico Biomimetico, Taglio a Risonanza Sonica Rigenerativa}\n",
        "\n",
        "Di seguito trovi l'elenco delle tecniche esistenti:\n",
        "{Affettamento a Pulsazioni Quantistiche, Affumicatura Polarizzata a Freddo Iperbarico, Affumicatura Psionica Sensoriale, Affumicatura Temporale Risonante, Affumicatura a Stratificazione Quantica, Affumicatura tramite Big Bang Microcosmico, Amalgamazione Sintetica Molecolare, Bollitura Entropica Sincronizzata, Bollitura Infrasonica Armonizzata, Bollitura Termografica a Rotazione Veloce, Congelamento Bio-Luminiscente Sincronico, Congelazione Iperdimensionalmente Stratificata, Cottura Idrodinamica Autoregolante, Cottura Olografica Quantum Fluttuante, Cottura Sottovuoto Antimateria, Cottura Sottovuoto Bioma Sintetico, Cottura Sottovuoto Frugale Energeticamente Negativa, Cottura Sottovuoto Multirealità Collassante, Cottura Sottovuoto Pulsar Magnetica, Cottura a Forno Dinamico Inversionale, Cottura a Vapore Ecodinamico Bilanciato, Cottura a Vapore Risonante Simbiotico, Cottura a Vapore Termocinetica Multipla, Cottura a Vapore con Flusso di Particelle Isoarmoniche, Cottura al Forno con Paradosso Temporale Cronospeculare, Cottura con Microonde Entropiche Sincronizzate, Cryo-Tessitura Energetica Polarizzata, Decostruzione Ancestrale, Decostruzione Atomica a Strati Energetici, Decostruzione Interdimensionale Lovecraftiana, Decostruzione Magnetica Risonante, Ebollizione Magneto-Cinetica Pulsante, Fermentazione Psionica Energetica, Fermentazione Quantica a Strati Multiversali, Fermentazione Quantico Biometrica, Fermentazione Temporale Sincronizzata, Grigliatura Eletro-Molecolare a Spaziatura Variabile, Grigliatura Plasma Sintetico Risonante, Grigliatura Psionica Dinamica Ritmica, Idro-Cristallizzazione Sonora Quantistica, Impasto Gravitazionale Vorticoso, Impasto a Campi Magnetici Dualistici, Incisione Elettromagnetica Plasmica, Marinatura Psionica, Marinatura Sotto Zero a Polarità Inversa, Marinatura Temporale Sincronizzata, Marinatura a Infusione Gravitazionale, Marinatura tramite Reazioni d'Antimateria Diluite, Modellatura Onirica Tetrazionale, Saltare in Padella Classica, Saltare in Padella Realtà Energetiche Parallele, Saltare in Padella Singolarità Inversa, Sferificazione Cromatica Interdimensionale, Sferificazione Filamentare a Molecole Vibrazionali, Sferificazione a Gravità Psionica Variabile, Sferificazione con Campi Magnetici Entropici, Sferificazione tramite Matrici Biofotiche, Sinergia Elettro-Osmotica Programmabile, Surgelamento Antimaterico a Risonanza Inversa, Taglio Dimensionale a Lame Fotofiliche, Taglio Sinaptico Biomimetico, Taglio a Risonanza Sonica Rigenerativa}\n",
        "\n",
        "\"\"\",  # Full prompt omitted for brevity\n",
        "        \"output_dir\": \"/content/Extracted_Constrained_Menu\",\n",
        "        \"description\": \"Extracts menu items with validated ingredients and techniques\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "G_g9vHODx8zu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Interactive Pipeline Execution\n",
        "\n",
        "def list_available_pipelines():\n",
        "    \"\"\"Display available extraction pipelines with descriptions.\"\"\"\n",
        "    print(\"\\nAvailable Extraction Pipelines:\")\n",
        "    print(\"-\" * 50)\n",
        "    for key, config in EXTRACTION_CONFIGS.items():\n",
        "        print(f\"\\n{config['name']} (key: '{key}')\")\n",
        "        print(f\"Description: {config['description']}\")\n",
        "        print(f\"Output directory: {config['output_dir']}\")\n",
        "    print(\"\\n\" + \"-\" * 50)\n",
        "\n",
        "def run_extraction_pipeline(extraction_type: str, input_dir: str):\n",
        "    \"\"\"\n",
        "    Run the specified extraction pipeline.\n",
        "\n",
        "    Args:\n",
        "        extraction_type (str): Type of extraction to perform\n",
        "        input_dir (str): Directory containing input PDFs\n",
        "    \"\"\"\n",
        "    if extraction_type not in EXTRACTION_CONFIGS:\n",
        "        print(f\"Error: Invalid extraction type '{extraction_type}'\")\n",
        "        list_available_pipelines()\n",
        "        return\n",
        "\n",
        "    config = EXTRACTION_CONFIGS[extraction_type]\n",
        "    print(f\"\\nRunning: {config['name']}\")\n",
        "    print(f\"Input directory: {input_dir}\")\n",
        "    print(f\"Output directory: {config['output_dir']}\")\n",
        "\n",
        "    try:\n",
        "        # Initialize and run pipeline\n",
        "        pipeline = MenuExtractionPipeline(config['output_dir'])\n",
        "        pipeline.process_directory(input_dir, config['prompt'])\n",
        "        print(f\"\\nExtraction completed successfully!\")\n",
        "        print(f\"Results saved in: {config['output_dir']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError during extraction: {str(e)}\")"
      ],
      "metadata": {
        "id": "9wrapHtTzZNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "list_available_pipelines()"
      ],
      "metadata": {
        "id": "mJ-hwoqczcB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_dir = \"/content/Raw_data_pdfs\"\n",
        "\n",
        "# To run a specific pipeline, uncomment and modify one of these lines:\n",
        "run_extraction_pipeline(\"metadata\", raw_data_dir)\n",
        "run_extraction_pipeline(\"menu_basic\", raw_data_dir)\n",
        "run_extraction_pipeline(\"menu_constrained\", raw_data_dir)"
      ],
      "metadata": {
        "id": "JZZQxeluuOWc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}